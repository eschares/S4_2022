{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7a0400",
   "metadata": {},
   "source": [
    "# Get OpenAlex results into a pandas DataFrame\n",
    "First we need to build the filter and get a response from the OpenAlex API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5021162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b434d3",
   "metadata": {},
   "source": [
    "Set how many results you want per page in OpenAlex. Max is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6b9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_page = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b913408",
   "metadata": {},
   "source": [
    "Define a function that rebuilds the filter every time to ask for the next page when your total results are larger than a single page.\n",
    "\n",
    "Adjust the filters for what you're looking for, then run this so we can call it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364f3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_filter(page):\n",
    "    # build the 'filter' parameter\n",
    "    filter_by_institution_id = 'institutions.ror:https://ror.org/03c4mmv16'\n",
    "    filter_by_paratext = 'is_paratext:false'   # not cover, ToC, issue information, etc\n",
    "    filter_by_type = 'type:dataset'\n",
    "    filter_by_publication_date = 'from_publication_date:2012-07-20&per-page='+str(per_page)\n",
    "    my_email = 'mailto=eschares@iastate.edu'\n",
    "    page = 'page='+str(page)\n",
    "\n",
    "    all_filters = (filter_by_institution_id, filter_by_paratext, filter_by_type, filter_by_publication_date)\n",
    "    filter_param = f'filter={\",\".join(all_filters)}'\n",
    "    filter_param = filter_param + '&' + my_email + '&' + page\n",
    "    #print(f'filter query parameter:\\n  {filter_param}')\n",
    "\n",
    "    # put the URL together\n",
    "    total_url = f'https://api.openalex.org/works?{filter_param}'\n",
    "    #print(f'complete URL:\\n  {total_url}')\n",
    "    return total_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07957d2",
   "metadata": {},
   "source": [
    "To test it, pass a 1 to the `build_filter` function to make a query for the first page of results. \n",
    "\n",
    "The 1 you pass controls the \"page=1\" part at the end of the API URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f6c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.openalex.org/works?filter=institutions.ror:https://ror.org/03c4mmv16,is_paratext:false,type:dataset,from_publication_date:2012-07-20&per-page=4&mailto=eschares@iastate.edu&page=1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_works_url = build_filter(1)\n",
    "filtered_works_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5131762",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a01d46",
   "metadata": {},
   "source": [
    "Send that test and get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54993978",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_response = requests.get(filtered_works_url)\n",
    "parsed_response = api_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea120570",
   "metadata": {},
   "source": [
    "How many results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c043795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_response['meta']['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaa8282",
   "metadata": {},
   "source": [
    "So how many pages will this take at the given per_page? \n",
    "\n",
    "(If it's less than a single page things start to get screwy, so try to set `per_page` so it goes beyond 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e32d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_response['meta']['count'] / per_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0eca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If it takes 1.5 pages to give me all my records (for example), we'll need to ask it for 2\n",
    "# To ask for 2, we'll need to set the range() to 3, since Python counts to stop-1\n",
    "\n",
    "number_of_pages_needed = int(parsed_response['meta']['count'] / per_page) + 2\n",
    "# need plus 2 to account for fractional page AND that python range stops 1 before end\n",
    "\n",
    "# BUT if the total number of records is cleanly divisible by the per-page (say, 33.0 pages)\n",
    "# we need to go back and remove one since the int() just drops the .0 and doesn't round\n",
    "if (parsed_response['meta']['count'] % per_page) == 0:\n",
    "    number_of_pages_needed -= 1\n",
    "    \n",
    "number_of_pages_needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca92fa",
   "metadata": {},
   "source": [
    "---\n",
    "## Here is where I run the OpenAlex call over and over, getting multiple pages.\n",
    "\n",
    "I save off the pieces of each record that I want to various lists using the .append; in my case I want the titles, years, DOIs, etc.\n",
    "\n",
    "Then after I collect all that data, I combine them into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfd66a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "\n",
      "https://api.openalex.org/works?filter=institutions.ror:https://ror.org/04rswrd78,is_paratext:false,type:journal-article,from_publication_date:2021-01-06,to_publication_date:2021-01-06&per-page=4&mailto=eschares@iastate.edu&page=1\n",
      "X-Ray Flow Visualization in Multiphase Flows, 102 references\n",
      "Synthetic glycosidases for the precise hydrolysis of oligosaccharides and polysaccharides, 45 references\n",
      "Accurately Differentiating Between Patients With COVID-19, Patients With Other Viral Infections, and Healthy Individuals: Multimodal Late Fusion Learning Approach, 50 references\n",
      "Effect of coil positioning and orientation of the quadruple butterfly coil during transcranial magnetic stimulation, 19 references\n",
      "Page 2\n",
      "\n",
      "https://api.openalex.org/works?filter=institutions.ror:https://ror.org/04rswrd78,is_paratext:false,type:journal-article,from_publication_date:2021-01-06,to_publication_date:2021-01-06&per-page=4&mailto=eschares@iastate.edu&page=2\n",
      "How do neuroglial cells respond to ultrasound induced cavitation?, 27 references\n",
      "Pre-exposure to hydrogen sulfide modulates the innate inflammatory response to organic dust, 58 references\n"
     ]
    }
   ],
   "source": [
    "# clear the lists \n",
    "publication_titles = []\n",
    "publication_year = []\n",
    "publication_journal = []\n",
    "publication_publisher = []\n",
    "publication_doi = []\n",
    "\n",
    "reference_years = []\n",
    "reference_titles = []\n",
    "reference_journal = []\n",
    "reference_publisher = []\n",
    "reference_doi = []\n",
    "\n",
    "# go through all the pages of results\n",
    "for page in range(1,number_of_pages_needed):   # offset already taken care of, don't need to +1 for range()\n",
    "    print(f'Page {page}\\n')                    # so if number_of_pages_needed is 3, variable 'page' will get 1 and 2\n",
    "        \n",
    "    # have to build the filter every time to ask for a new page\n",
    "    filtered_works_url = build_filter(page)\n",
    "    print(filtered_works_url)\n",
    "    \n",
    "    # Send it and get a response\n",
    "    api_response = requests.get(filtered_works_url)\n",
    "    parsed_response = api_response.json()\n",
    "\n",
    "    # deal with fractional pages, need to keep track of how many leftover on the last page to avoid indexing error\n",
    "    if page < (number_of_pages_needed-1):\n",
    "        how_many_records = per_page\n",
    "    else:  # figure out how many left on last page and only pass that many\n",
    "        how_many_records = parsed_response['meta']['count'] - ((page-1) * per_page)\n",
    "                                    # total records         -  pagesdone * records-per-page\n",
    "        #print(f\"page {page} num needed {number_of_pages_needed} how many records {how_many_records} total {parsed_response['meta']['count']} per page {per_page}\")\n",
    "        \n",
    "    \n",
    "    # Here is where you look into each record and pull out what you want\n",
    "    \n",
    "    for j in range(how_many_records):  # controls number of records to look at per page; 0 to per_page-1\n",
    "        print(f\"{parsed_response['results'][j]['title']}, {len(parsed_response['results'][j]['referenced_works'])} references\")\n",
    "        \n",
    "        for i in parsed_response['results'][j]['referenced_works']:   #number of referenced works in the paper j\n",
    "            splat = i.split('/')\n",
    "            entity = splat[3]  #W1537479324\n",
    "\n",
    "            single_work = requests.get('https://api.openalex.org/works/'+entity)\n",
    "            parsed_single_work = single_work.json()\n",
    "\n",
    "            # append the part you want to your lists\n",
    "            reference_years.append(parsed_single_work['publication_year'])\n",
    "            reference_titles.append(parsed_single_work['title'])\n",
    "            reference_journal.append(parsed_single_work['host_venue']['display_name'])\n",
    "            reference_publisher.append(parsed_single_work['host_venue']['publisher'])\n",
    "            reference_doi.append(parsed_single_work['doi'])\n",
    "\n",
    "            publication_year.append(parsed_response['results'][j]['publication_year'])\n",
    "            publication_titles.append(parsed_response['results'][j]['title'])\n",
    "            publication_journal.append(parsed_response['results'][j]['host_venue']['display_name'])\n",
    "            publication_publisher.append(parsed_response['results'][j]['host_venue']['publisher'])\n",
    "            publication_doi.append(parsed_response['results'][j]['doi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a15a45",
   "metadata": {},
   "source": [
    "---\n",
    "Check of the list lengths, should be all the same for the dataframe to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c0f0031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of referenced years: 301\n",
      "Length of referenced titles: 301\n",
      "Length of referenced journals: 301\n",
      "Length of publication year: 301\n",
      "Length of publication titles: 301\n",
      "Length of publication journals: 301\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of referenced years: {len(reference_years)}')\n",
    "print(f'Length of referenced titles: {len(reference_titles)}')\n",
    "print(f'Length of referenced journals: {len(reference_journal)}')\n",
    "\n",
    "print(f'Length of publication year: {len(publication_year)}')\n",
    "print(f'Length of publication titles: {len(publication_titles)}')\n",
    "print(f'Length of publication journals: {len(publication_journal)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51adf5f9",
   "metadata": {},
   "source": [
    "### Make the lists into a dataframe in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1bc451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication</th>\n",
       "      <th>publication_doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_journal</th>\n",
       "      <th>referenced_title</th>\n",
       "      <th>reference_doi</th>\n",
       "      <th>referenced_year</th>\n",
       "      <th>referenced_journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X-Ray Flow Visualization in Multiphase Flows</td>\n",
       "      <td>https://doi.org/10.1146/annurev-fluid-010719-0...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Annual Review of Fluid Mechanics</td>\n",
       "      <td>Industrial tomography using three different ga...</td>\n",
       "      <td>https://doi.org/10.1016/j.flowmeasinst.2015.10...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Flow Measurement and Instrumentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X-Ray Flow Visualization in Multiphase Flows</td>\n",
       "      <td>https://doi.org/10.1146/annurev-fluid-010719-0...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Annual Review of Fluid Mechanics</td>\n",
       "      <td>Quantitative measurement of gas hold-up distri...</td>\n",
       "      <td>https://doi.org/10.1016/j.cej.2007.08.014</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chemical Engineering Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X-Ray Flow Visualization in Multiphase Flows</td>\n",
       "      <td>https://doi.org/10.1146/annurev-fluid-010719-0...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Annual Review of Fluid Mechanics</td>\n",
       "      <td>Gamma‐Ray Computed Tomography for Imaging of M...</td>\n",
       "      <td>https://doi.org/10.1002/cite.201200250</td>\n",
       "      <td>2013</td>\n",
       "      <td>Chemie Ingenieur Technik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    publication  \\\n",
       "0  X-Ray Flow Visualization in Multiphase Flows   \n",
       "1  X-Ray Flow Visualization in Multiphase Flows   \n",
       "2  X-Ray Flow Visualization in Multiphase Flows   \n",
       "\n",
       "                                     publication_doi  publication_year  \\\n",
       "0  https://doi.org/10.1146/annurev-fluid-010719-0...              2021   \n",
       "1  https://doi.org/10.1146/annurev-fluid-010719-0...              2021   \n",
       "2  https://doi.org/10.1146/annurev-fluid-010719-0...              2021   \n",
       "\n",
       "                publication_journal  \\\n",
       "0  Annual Review of Fluid Mechanics   \n",
       "1  Annual Review of Fluid Mechanics   \n",
       "2  Annual Review of Fluid Mechanics   \n",
       "\n",
       "                                    referenced_title  \\\n",
       "0  Industrial tomography using three different ga...   \n",
       "1  Quantitative measurement of gas hold-up distri...   \n",
       "2  Gamma‐Ray Computed Tomography for Imaging of M...   \n",
       "\n",
       "                                       reference_doi  referenced_year  \\\n",
       "0  https://doi.org/10.1016/j.flowmeasinst.2015.10...             2016   \n",
       "1          https://doi.org/10.1016/j.cej.2007.08.014             2008   \n",
       "2             https://doi.org/10.1002/cite.201200250             2013   \n",
       "\n",
       "                     referenced_journal  \n",
       "0  Flow Measurement and Instrumentation  \n",
       "1          Chemical Engineering Journal  \n",
       "2              Chemie Ingenieur Technik  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what you want to call the column : list name\n",
    "d = {'publication':publication_titles,\n",
    "     'publication_doi':publication_doi,\n",
    "     'publication_year':publication_year,\n",
    "     'publication_journal':publication_journal,\n",
    "     'referenced_title':reference_titles,\n",
    "     'reference_doi':reference_doi,\n",
    "     'referenced_year':reference_years,\n",
    "     'referenced_journal':reference_journal\n",
    "    }\n",
    "df = pd.DataFrame(data=d)  # make the dataframe\n",
    "df.head(3)  #check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a6b679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_year</th>\n",
       "      <th>referenced_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>301.0</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>2011.850498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.790858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>1950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       publication_year  referenced_year\n",
       "count             301.0       301.000000\n",
       "mean             2021.0      2011.850498\n",
       "std                 0.0         9.790858\n",
       "min              2021.0      1950.000000\n",
       "25%              2021.0      2008.000000\n",
       "50%              2021.0      2015.000000\n",
       "75%              2021.0      2019.000000\n",
       "max              2021.0      2021.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary statistics of number columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01e2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
